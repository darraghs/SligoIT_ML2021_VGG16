{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a579a764",
   "metadata": {},
   "source": [
    "# Assignment 2 - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655dd02",
   "metadata": {},
   "source": [
    "#### Darragh Sherwin - S00217114"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb2973",
   "metadata": {},
   "source": [
    "Install Keras if neeeded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767857f",
   "metadata": {},
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90609721",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb5cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd1adc",
   "metadata": {},
   "source": [
    "Download the kaggle data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e56e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/kaggle-data-sets/82373/191501/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20211230/auto/storage/goog4_request&X-Goog-Date=20211230T164750Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=3ec2cc63a76c721c9aa50493eabd02e0a3d4450104838e8309f2c395590a86609c8187f3228eabae17d0468e56dc1ebd4c6181a1494e9b85295ba4aafc138de8406286a63c281d755526c579432344ec85c5abe83dadbdc8abe01eed554b05090bfc7c6aef1d20f805e9545fc5902c501a04d45c7aba0104323e727efefaaa10ef5454516602b39628be2bf330860ac3f6f02328e8d45e8b915940a10078f320ec725f7a109e6232e1e8fccb66b7e9b548d4167c3da544e5cab200f25aaa9ef328ea0031c3910be36652ab27348ba0e8c386f8460c74da42ec0d990961c1039b04b20939a605a685312c250dcde8f2fcd3c3a61fe36cf3c1057f14050fb9665e'\n",
    "#path_to_zip = keras.utils.get_file('archive.zip', origin=_URL, extract=True)\n",
    "path_to_zip='/Users/dsherwin/courses/machine_learning/SligoIT_ML2021_VGG16/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b40cc5",
   "metadata": {},
   "source": [
    "Setup paths to train and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c059f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dsherwin/courses/machine_learning/SligoIT_ML2021_VGG16/data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.dirname(path_to_zip)\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4852c137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dsherwin/courses/machine_learning/SligoIT_ML2021_VGG16/data/Train'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(DATA_PATH, 'Train')\n",
    "test_dir = os.path.join(DATA_PATH, 'Test')\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09361888",
   "metadata": {},
   "source": [
    "Test data is uncategorized, so need to move it into categorical directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "180da603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(os.path.join(DATA_PATH, 'Test.csv'))\n",
    "df['Path'] =df['Path'].apply( lambda x: x.replace('Test/','') )\n",
    "df.to_csv(os.path.join(DATA_PATH, 'Test1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a754fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(path_to_image,path_file):\n",
    "\n",
    "    with open(path_file,\"r\") as csvfile:\n",
    "        r= csv.reader(csvfile,delimiter =',')\n",
    "  \n",
    "        for i,row in enumerate(r):\n",
    "            if i == 0: \n",
    "                continue\n",
    "            label = row[-2]\n",
    "            img_name = row[-1]\n",
    "            \n",
    "            dest = os.path.join(test_dir,label)\n",
    "            if not os.path.isdir(dest):\n",
    "                os.makedirs(dest)\n",
    "            \n",
    "            to_move = os.path.join(path_to_image,img_name)\n",
    "            shutil.copy(to_move,dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3ed7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "path_file =os.path.join(DATA_PATH, 'Test1.csv')\n",
    "prepare_test(test_dir,path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4bb56",
   "metadata": {},
   "source": [
    "Setup Data Generators for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3932b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n",
      "Found 12630 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d0e96",
   "metadata": {},
   "source": [
    "Taken from https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1abd1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "    \n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2218149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-31 03:45:39.579056: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-31 03:45:39.580999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "n_classes=43\n",
    "\n",
    "n_steps = traindata.samples // 32\n",
    "n_val_steps = testdata.samples // 32\n",
    "n_epochs = 50\n",
    "\n",
    "# First we'll train the model without Fine-tuning\n",
    "vgg_model = create_model(input_shape, n_classes, optim_1, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "425694a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting livelossplot\n",
      "  Downloading livelossplot-0.5.4-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from livelossplot) (3.4.2)\n",
      "Requirement already satisfied: ipython in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from livelossplot) (7.26.0)\n",
      "Requirement already satisfied: bokeh in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from livelossplot) (2.3.3)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (5.4.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (3.10.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (1.20.3)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (2.11.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from bokeh->livelossplot) (8.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
      "Requirement already satisfied: pygments in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (0.17.2)\n",
      "Requirement already satisfied: decorator in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (5.0.9)\n",
      "Requirement already satisfied: backcall in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pickleshare in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (3.0.17)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (5.0.5)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (0.1.2)\n",
      "Requirement already satisfied: appnope in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from ipython->livelossplot) (0.1.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython->livelossplot) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython->livelossplot) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->livelossplot) (1.3.1)\n",
      "Installing collected packages: livelossplot\n",
      "Successfully installed livelossplot-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c220da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_config' from 'tensorflow.python.eager.context' (/Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xf/t050gw_x4rq1sypmmzm7q5s80000gn/T/ipykernel_3859/34029732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLossesCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_loss_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlotLossesCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ModelCheckpoint callback - save best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/livelossplot/inputs/keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneric_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_PlotLossesCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/Users/dsherwin/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py)"
     ]
    }
   ],
   "source": [
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "\n",
    "plot_loss_1 = PlotLossesCallback()\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_v1.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8734251",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "vgg_history = vgg_model.fit(traindata,\n",
    "                            batch_size=32,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=testdata,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f84b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "vgg_model.load_weights('tl_model_v1.weights.best.hdf5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testdata.classes\n",
    "class_indices = traindata.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds = vgg_model.predict(testdata)\n",
    "vgg_pred_classes = np.argmax(vgg_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes)\n",
    "print(\"VGG16 Model Accuracy without Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
