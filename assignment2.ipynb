{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a579a764",
   "metadata": {},
   "source": [
    "# Assignment 2 - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655dd02",
   "metadata": {},
   "source": [
    "#### Darragh Sherwin - S00217114"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb2973",
   "metadata": {},
   "source": [
    "Install Keras if neeeded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767857f",
   "metadata": {},
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90609721",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "feb5cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd1adc",
   "metadata": {},
   "source": [
    "Download the kaggle data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e56e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/kaggle-data-sets/82373/191501/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20211230/auto/storage/goog4_request&X-Goog-Date=20211230T164750Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=3ec2cc63a76c721c9aa50493eabd02e0a3d4450104838e8309f2c395590a86609c8187f3228eabae17d0468e56dc1ebd4c6181a1494e9b85295ba4aafc138de8406286a63c281d755526c579432344ec85c5abe83dadbdc8abe01eed554b05090bfc7c6aef1d20f805e9545fc5902c501a04d45c7aba0104323e727efefaaa10ef5454516602b39628be2bf330860ac3f6f02328e8d45e8b915940a10078f320ec725f7a109e6232e1e8fccb66b7e9b548d4167c3da544e5cab200f25aaa9ef328ea0031c3910be36652ab27348ba0e8c386f8460c74da42ec0d990961c1039b04b20939a605a685312c250dcde8f2fcd3c3a61fe36cf3c1057f14050fb9665e\n",
      "641572864/641568792 [==============================] - 119s 0us/step\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://storage.googleapis.com/kaggle-data-sets/82373/191501/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com/20211230/auto/storage/goog4_request&X-Goog-Date=20211230T164750Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=3ec2cc63a76c721c9aa50493eabd02e0a3d4450104838e8309f2c395590a86609c8187f3228eabae17d0468e56dc1ebd4c6181a1494e9b85295ba4aafc138de8406286a63c281d755526c579432344ec85c5abe83dadbdc8abe01eed554b05090bfc7c6aef1d20f805e9545fc5902c501a04d45c7aba0104323e727efefaaa10ef5454516602b39628be2bf330860ac3f6f02328e8d45e8b915940a10078f320ec725f7a109e6232e1e8fccb66b7e9b548d4167c3da544e5cab200f25aaa9ef328ea0031c3910be36652ab27348ba0e8c386f8460c74da42ec0d990961c1039b04b20939a605a685312c250dcde8f2fcd3c3a61fe36cf3c1057f14050fb9665e'\n",
    "path_to_zip = keras.utils.get_file('archive.zip', origin=_URL, extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b40cc5",
   "metadata": {},
   "source": [
    "Setup paths to train and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c059f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.dirname(path_to_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4852c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATA_PATH, 'Train')\n",
    "test_dir = os.path.join(DATA_PATH, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09361888",
   "metadata": {},
   "source": [
    "Test data is uncategorized, so need to move it into categorical directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "180da603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(os.path.join(DATA_PATH, 'Test.csv'))\n",
    "df['Path'] =df['Path'].apply( lambda x: x.replace('Test/','') )\n",
    "df.to_csv(os.path.join(DATA_PATH, 'Test1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a754fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(path_to_image,path_file):\n",
    "\n",
    "    with open(path_file,\"r\") as csvfile:\n",
    "        r= csv.reader(csvfile,delimiter =',')\n",
    "  \n",
    "        for i,row in enumerate(r):\n",
    "            if i == 0: \n",
    "                continue\n",
    "            label = row[-2]\n",
    "            img_name = row[-1]\n",
    "            \n",
    "            dest = os.path.join(test_dir,label)\n",
    "            if not os.path.isdir(dest):\n",
    "                os.makedirs(dest)\n",
    "            \n",
    "            to_move = os.path.join(path_to_image,img_name)\n",
    "            shutil.copy(to_move,dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3ed7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "path_file =os.path.join(DATA_PATH, 'Test1.csv')\n",
    "prepare_test(test_dir,path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4bb56",
   "metadata": {},
   "source": [
    "Setup Data Generators for train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d3932b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n",
      "Found 12630 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78fda920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x7fc2fa47d790>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d0e96",
   "metadata": {},
   "source": [
    "Taken from https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1abd1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with VGG16 pretrained layers\n",
    "    \n",
    "    input_shape: tuple - the shape of input images (width, height, channels)\n",
    "    n_classes: int - number of classes for the output layer\n",
    "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
    "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
    "                If set to 0, all pretrained layers will freeze during training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2218149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 20:13:25.311293: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-30 20:13:25.315031: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 84s 1us/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "n_classes=43\n",
    "\n",
    "n_steps = traindata.samples // 32\n",
    "n_val_steps = testdata.samples // 32\n",
    "n_epochs = 50\n",
    "\n",
    "# First we'll train the model without Fine-tuning\n",
    "vgg_model = create_model(input_shape, n_classes, optim_1, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c220da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xf/t050gw_x4rq1sypmmzm7q5s80000gn/T/ipykernel_36163/1853463962.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Loading VGG16 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m## Not trainable weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## Preprocessing input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "\n",
    "plot_loss_1 = PlotLossesCallback()\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_v1.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8734251",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "vgg_history = vgg_model.fit(traindata,\n",
    "                            batch_size=32,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=testdata,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1, early_stop, plot_loss_1],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f84b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "vgg_model.load_weights('tl_model_v1.weights.best.hdf5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds = vgg_model.predict(testgen)\n",
    "vgg_pred_classes = np.argmax(vgg_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes)\n",
    "print(\"VGG16 Model Accuracy without Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
